{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    #Load the row data from the file \n",
    "    data = pd.read_csv('../data/Africa_Vectors_database_1898-2016.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    # remove white spaces at the begining and end of column names and labels in the columns\n",
    "    Region = 'GAUL_Admin2'\n",
    "    data.columns = data.columns.str.strip()\n",
    "    data['Country']= data['Country'].str.strip()\n",
    "    data[Region]= data[Region].str.strip()\n",
    "    data['Adults/Larvae']= data['Adults/Larvae'].str.strip()\n",
    "\n",
    "    # convert the 3 columns to Upper case\n",
    "    data['Country'] = data['Country'].str.upper()\n",
    "    data[Region] = data[Region].str.upper()\n",
    "    data['Adults/Larvae'] = data['Adults/Larvae'].str.upper()\n",
    "\n",
    "    #change the column name of Full_Name to Region\n",
    "    data = data.rename(columns={Region: 'Region'})\n",
    "\n",
    "    #Taking the mean over the two years, round is to make sure we do not have decimals in years \n",
    "    data['Year'] = list(round(data[['YeStart', 'YeEnd']].mean(axis=1)))\n",
    "\n",
    "    #Selecting the features to keep\n",
    "    features =['Country','Region', 'Lat', 'Long','Year', 'An gambiae_complex', 'An gambiae ss', 'SS M Form (An colluzzi or Mopti forms)', 'SS S Form (savanah or Bamako forms)','An arabiensis','An. melas','An. merus','An bwambae','An funestus  s.l','An funestus s.s. (specified)','An rivulorum','An leesoni','An parensis','An vaneedeni','An nili s.l','An moucheti s.l','An pharoensis','An hancocki','An mascarensis','An marshalli','An squamous','An wellcomei','An rufipes','An coustani s.l','An ziemanni','An paludis','Adults/Larvae']\n",
    "\n",
    "    #Returning a dataset with only the features kept\n",
    "    featured_data= data[features]\n",
    "\n",
    "    #remove records with Lat,Long missing values \n",
    "    featured_data = featured_data.dropna(axis=0, subset=['Lat'])\n",
    "\n",
    "    #encoding the species classes \n",
    "    encoded_data = featured_data.replace(np.nan,0).replace('Y',1)\n",
    "\n",
    "    # Reseting the  index\n",
    "    encoded_data=encoded_data.reset_index(drop=True)\n",
    "\n",
    "    #encoding the labels columns \n",
    "    # Label encoding for Country, Region, and  Adults/Larvae columns \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    encoded_data['Country'] = le.fit_transform(encoded_data['Country'])\n",
    "    encoded_data['Adults/Larvae'] = le.fit_transform(encoded_data['Adults/Larvae'])\n",
    "    encoded_data['Region'] = le.fit_transform(encoded_data['Region'].astype(str))\n",
    "    \n",
    "    #normalize the data\n",
    "    #encoded_data=(encoded_data-encoded_data.mean())/encoded_data.std()\n",
    "\n",
    "    \n",
    "    #normalize the longitude and latitude \n",
    "#     encoded_data['Lat']=(encoded_data['Lat']-encoded_data['Lat'].mean())/encoded_data['Lat'].std()\n",
    "#     encoded_data['Long']=(encoded_data['Long']-encoded_data['Long'].mean())/encoded_data['Long'].std()\n",
    "#     encoded_data['Year']=(encoded_data['Year']-encoded_data['Year'].mean())/encoded_data['Year'].std()\n",
    "      \n",
    "    #feature scaling for year, longitude and latitude \n",
    "    encoded_data['Lat']=(encoded_data['Lat']-encoded_data['Lat'].min())/encoded_data['Lat'].max()\n",
    "    encoded_data['Long']=(encoded_data['Long']-encoded_data['Long'].min())/encoded_data['Long'].max()\n",
    "    encoded_data['Year']=(encoded_data['Year']-encoded_data['Year'].min())/encoded_data['Year'].max()\n",
    "\n",
    "    #convert the year column from float to int \n",
    "    #data = data.astype({'Year':'int'})\n",
    "    encoded_data = shuffle(encoded_data)\n",
    "\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a916029d0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing datasets \n",
    "inputs = get_data().values[:,4:] #species columns \n",
    "targets = get_data().values[:,0] #Lat & Long\n",
    "train_inputs = torch.tensor(inputs[0:9000]).float().to(device)\n",
    "train_targets = torch.tensor(targets[0:9000]).long().to(device)\n",
    "test_inputs = torch.tensor(inputs[9000:]).float().to(device)\n",
    "test_targets = torch.tensor(targets[9000:]).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D = train_inputs.shape\n",
    "C = test_targets.shape\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self,n_hidden):\n",
    "        super(model, self).__init__()\n",
    "        self.batch_momentum = 0.999\n",
    "        self.track_running_stats= True\n",
    "        self.block1 = nn.Sequential(\n",
    "        nn.Linear(D, n_hidden), # layer 1 \n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        ) #100\n",
    "        \n",
    "        self.block2 = nn.Sequential(         \n",
    "        nn.Linear(n_hidden, n_hidden), # layer 2\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden), # layer 3\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "        #100\n",
    "        \n",
    "        self.block3 = nn.Sequential(  \n",
    "        nn.Linear(n_hidden,n_hidden), # layer 4\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden), # layer 5\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        )#100\n",
    "        \n",
    "        self.block4 = nn.Sequential(  \n",
    "        nn.Linear(n_hidden,48), # layer 6\n",
    "        )#48\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        residual1 = x   #Save input as residual\n",
    "\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        \n",
    "        x += residual1 #add input to output of block2\n",
    "        residual2 = x  #save output of block1 as residual\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        x += residual2 #add input to output of block2\n",
    "        \n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model):\n",
    "    model.train()\n",
    "    for data,target in zip(train_inputs.split(batch_size),train_targets.split(batch_size)):\n",
    "        output = model(data)\n",
    "        #print(100)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch%10 == 0):\n",
    "        train_losses.append(loss.item())\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f\" % (epoch, loss.item()))\n",
    "        \n",
    "\n",
    "def test(model):\n",
    "#     for _ in range(2):\n",
    "#         model(torch.FloatTensor(2,28))#https://discuss.pytorch.org/t/model-eval-gives-incorrect-loss-for-model-with-batchnorm-layers/7561/2\n",
    "    #model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data,target in zip(test_inputs.split(batch_size),test_targets.split(batch_size)):\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target,reduction='sum').item()#/test_inputs.shape[0]  # sum up batch loss instead of averaging by multplying the batch size                                                           \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    test_loss /= test_inputs.shape[0]\n",
    "    test_losses.append(test_loss)\n",
    "    accuracy = 100. * correct / test_inputs.shape[0]\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy:({:.0f}%)\\n'.format(test_loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = model(100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimization paramaters\n",
    "lr = 1e-3\n",
    "lambda_l2 = 1e-5\n",
    "nb_epoches = 1000\n",
    "batch_size =  60\n",
    "#criterion = torch.nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(Net.parameters(), lr=lr, momentum=0.5) # built-in L2\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lambda_l2) # built-in L2\n",
    "optimizer = torch.optim.Adam(Net.parameters(), lr=lr, weight_decay=lambda_l2) # built-in L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'checkpoint.pth.tar'\n",
    "epoch = 0\n",
    "test_losses = []\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "=> loading checkpoint 'checkpoint.pth.tar'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for model:\n\tMissing key(s) in state_dict: \"block1.1.running_mean\", \"block1.1.running_var\", \"block1.1.num_batches_tracked\", \"block2.1.running_mean\", \"block2.1.running_var\", \"block2.1.num_batches_tracked\", \"block2.4.running_mean\", \"block2.4.running_var\", \"block2.4.num_batches_tracked\", \"block3.1.running_mean\", \"block3.1.running_var\", \"block3.1.num_batches_tracked\", \"block3.4.running_mean\", \"block3.4.running_var\", \"block3.4.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-9c076d034ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_losses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 723\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for model:\n\tMissing key(s) in state_dict: \"block1.1.running_mean\", \"block1.1.running_var\", \"block1.1.num_batches_tracked\", \"block2.1.running_mean\", \"block2.1.running_var\", \"block2.1.num_batches_tracked\", \"block2.4.running_mean\", \"block2.4.running_var\", \"block2.4.num_batches_tracked\", \"block3.1.running_mean\", \"block3.1.running_var\", \"block3.1.num_batches_tracked\", \"block3.4.running_mean\", \"block3.4.running_var\", \"block3.4.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "# save and load the model \n",
    "# print(file_name)\n",
    "import os \n",
    "if file_name:\n",
    "        print('in')\n",
    "        if os.path.isfile(file_name):\n",
    "            print(\"=> loading checkpoint '{}'\".format(file_name))\n",
    "            checkpoint = torch.load(file_name)\n",
    "            epoch = checkpoint['epoch']\n",
    "            Net.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            test_losses = checkpoint['test_losses']\n",
    "            train_losses = checkpoint['train_losses']\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(file_name, checkpoint['epoch']))\n",
    "            #Net.eval() #https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/8\n",
    "\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(file_name))\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    file_name = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 0, [LOSS]: 3.425701\n",
      "[EPOCH]: 10, [LOSS]: 3.066779\n",
      "\n",
      "Test set: Average loss: 4.0403, Accuracy:(7%)\n",
      "\n",
      "[EPOCH]: 20, [LOSS]: 2.593553\n",
      "[EPOCH]: 30, [LOSS]: 2.245961\n",
      "\n",
      "Test set: Average loss: 5.3820, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 40, [LOSS]: 1.812386\n",
      "[EPOCH]: 50, [LOSS]: 1.628565\n",
      "\n",
      "Test set: Average loss: 6.9434, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 60, [LOSS]: 1.315942\n",
      "[EPOCH]: 70, [LOSS]: 1.285357\n",
      "\n",
      "Test set: Average loss: 8.3966, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 80, [LOSS]: 1.147345\n",
      "[EPOCH]: 90, [LOSS]: 0.954661\n",
      "\n",
      "Test set: Average loss: 9.4313, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 100, [LOSS]: 0.927770\n",
      "[EPOCH]: 110, [LOSS]: 0.845915\n",
      "\n",
      "Test set: Average loss: 10.3517, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 120, [LOSS]: 0.772127\n",
      "[EPOCH]: 130, [LOSS]: 0.743814\n",
      "\n",
      "Test set: Average loss: 10.9324, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 140, [LOSS]: 0.794315\n",
      "[EPOCH]: 150, [LOSS]: 0.697620\n",
      "\n",
      "Test set: Average loss: 11.4530, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 160, [LOSS]: 0.982486\n",
      "[EPOCH]: 170, [LOSS]: 0.751437\n",
      "\n",
      "Test set: Average loss: 11.8318, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 180, [LOSS]: 0.587025\n",
      "[EPOCH]: 190, [LOSS]: 0.617116\n",
      "\n",
      "Test set: Average loss: 12.2057, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 200, [LOSS]: 0.810903\n",
      "[EPOCH]: 210, [LOSS]: 0.707566\n",
      "\n",
      "Test set: Average loss: 12.5373, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 220, [LOSS]: 0.569808\n",
      "[EPOCH]: 230, [LOSS]: 0.589449\n",
      "\n",
      "Test set: Average loss: 12.8244, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 240, [LOSS]: 0.695254\n",
      "[EPOCH]: 250, [LOSS]: 0.773824\n",
      "\n",
      "Test set: Average loss: 13.0317, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 260, [LOSS]: 0.692984\n",
      "[EPOCH]: 270, [LOSS]: 0.580121\n",
      "\n",
      "Test set: Average loss: 13.2923, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 280, [LOSS]: 0.573982\n",
      "[EPOCH]: 290, [LOSS]: 0.528978\n",
      "\n",
      "Test set: Average loss: 13.5681, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 300, [LOSS]: 0.598174\n",
      "[EPOCH]: 310, [LOSS]: 0.497949\n",
      "\n",
      "Test set: Average loss: 13.6738, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 320, [LOSS]: 0.544007\n",
      "[EPOCH]: 330, [LOSS]: 0.642335\n",
      "\n",
      "Test set: Average loss: 13.7795, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 340, [LOSS]: 0.422924\n",
      "[EPOCH]: 350, [LOSS]: 0.527479\n",
      "\n",
      "Test set: Average loss: 14.0174, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 360, [LOSS]: 0.588742\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-60557dd5ef12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-c18b9822d050>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print(100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-4787a7370ca7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mresidual1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m   \u001b[0;31m#Save input as residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         return F.batch_norm(\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             exponential_average_factor, self.eps)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0m_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_buffers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_modules'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_modules'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while (1):\n",
    "    train(epoch,Net)\n",
    "    epoch += 1\n",
    "    if(epoch%20 ==0):\n",
    "        test(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 19.1702, Accuracy:(4%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange((len(train_losses)))*10,np.array(train_losses))\n",
    "plt.plot(np.arange((len(test_losses)))*10,np.array(test_losses))\n",
    "plt.xlabel('no of iterations')\n",
    "plt.legend(['test avarage loss', 'training loss'], loc='upper left')\n",
    "l2 = train_losses\n",
    "plt.savefig('test vs training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': Net.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
