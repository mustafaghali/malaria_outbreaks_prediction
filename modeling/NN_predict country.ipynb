{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    #Load the row data from the file \n",
    "    data = pd.read_csv('../data/Africa_Vectors_database_1898-2016.csv', sep = ',', encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    # remove white spaces at the begining and end of column names and labels in the columns\n",
    "    Region = 'GAUL_Admin2'\n",
    "    data.columns = data.columns.str.strip()\n",
    "    data['Country']= data['Country'].str.strip()\n",
    "    data[Region]= data[Region].str.strip()\n",
    "    data['Adults/Larvae']= data['Adults/Larvae'].str.strip()\n",
    "\n",
    "    # convert the 3 columns to Upper case\n",
    "    data['Country'] = data['Country'].str.upper()\n",
    "    data[Region] = data[Region].str.upper()\n",
    "    data['Adults/Larvae'] = data['Adults/Larvae'].str.upper()\n",
    "\n",
    "    #change the column name of Full_Name to Region\n",
    "    data = data.rename(columns={Region: 'Region'})\n",
    "\n",
    "    #Taking the mean over the two years, round is to make sure we do not have decimals in years \n",
    "    data['Year'] = list(round(data[['YeStart', 'YeEnd']].mean(axis=1)))\n",
    "\n",
    "    #Selecting the features to keep\n",
    "    features =['Country','Region', 'Lat', 'Long','Year', 'An gambiae_complex', 'An gambiae ss', 'SS M Form (An colluzzi or Mopti forms)', 'SS S Form (savanah or Bamako forms)','An arabiensis','An. melas','An. merus','An bwambae','An funestus  s.l','An funestus s.s. (specified)','An rivulorum','An leesoni','An parensis','An vaneedeni','An nili s.l','An moucheti s.l','An pharoensis','An hancocki','An mascarensis','An marshalli','An squamous','An wellcomei','An rufipes','An coustani s.l','An ziemanni','An paludis','Adults/Larvae']\n",
    "\n",
    "    #Returning a dataset with only the features kept\n",
    "    featured_data= data[features]\n",
    "\n",
    "    #remove records with Lat,Long missing values \n",
    "    featured_data = featured_data.dropna(axis=0, subset=['Lat'])\n",
    "\n",
    "    #encoding the species classes \n",
    "    encoded_data = featured_data.replace(np.nan,0).replace('Y',1)\n",
    "\n",
    "    # Reseting the  index\n",
    "    encoded_data=encoded_data.reset_index(drop=True)\n",
    "\n",
    "    #encoding the labels columns \n",
    "    # Label encoding for Country, Region, and  Adults/Larvae columns \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    encoded_data['Country'] = le.fit_transform(encoded_data['Country'])\n",
    "    encoded_data['Adults/Larvae'] = le.fit_transform(encoded_data['Adults/Larvae'])\n",
    "    encoded_data['Region'] = le.fit_transform(encoded_data['Region'].astype(str))\n",
    "    \n",
    "    #normalize the data\n",
    "    #encoded_data=(encoded_data-encoded_data.mean())/encoded_data.std()\n",
    "\n",
    "    \n",
    "    #normalize the longitude and latitude \n",
    "#     encoded_data['Lat']=(encoded_data['Lat']-encoded_data['Lat'].mean())/encoded_data['Lat'].std()\n",
    "#     encoded_data['Long']=(encoded_data['Long']-encoded_data['Long'].mean())/encoded_data['Long'].std()\n",
    "#     encoded_data['Year']=(encoded_data['Year']-encoded_data['Year'].mean())/encoded_data['Year'].std()\n",
    "      \n",
    "    #feature scaling for year, longitude and latitude \n",
    "    encoded_data['Lat']=(encoded_data['Lat']-encoded_data['Lat'].min())/encoded_data['Lat'].max()\n",
    "    encoded_data['Long']=(encoded_data['Long']-encoded_data['Long'].min())/encoded_data['Long'].max()\n",
    "    encoded_data['Year']=(encoded_data['Year']-encoded_data['Year'].min())/encoded_data['Year'].max()\n",
    "\n",
    "    #convert the year column from float to int \n",
    "    #data = data.astype({'Year':'int'})\n",
    "    encoded_data = shuffle(encoded_data)\n",
    "\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a93b989f0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing datasets \n",
    "inputs = get_data().values[:,4:] #species columns \n",
    "targets = get_data().values[:,0] #Lat & Long\n",
    "train_inputs = torch.tensor(inputs[0:9000]).float().to(device)\n",
    "train_targets = torch.tensor(targets[0:9000]).long().to(device)\n",
    "test_inputs = torch.tensor(inputs[9000:]).float().to(device)\n",
    "test_targets = torch.tensor(targets[9000:]).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D = train_inputs.shape\n",
    "C = test_targets.shape\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self,n_hidden):\n",
    "        super(model, self).__init__()\n",
    "        self.batch_momentum = 0.999\n",
    "        self.track_running_stats= True\n",
    "        self.block1 = nn.Sequential(\n",
    "        nn.Linear(D, n_hidden), # layer 1 \n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        ) #100\n",
    "        \n",
    "        self.block2 = nn.Sequential(         \n",
    "        nn.Linear(n_hidden, n_hidden), # layer 2\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden), # layer 3\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "        #100\n",
    "        \n",
    "        self.block3 = nn.Sequential(  \n",
    "        nn.Linear(n_hidden,n_hidden), # layer 4\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden), # layer 5\n",
    "        nn.BatchNorm1d(n_hidden,momentum=self.batch_momentum,track_running_stats=self.track_running_stats),\n",
    "        nn.ReLU(),\n",
    "        )#100\n",
    "        \n",
    "        self.block4 = nn.Sequential(  \n",
    "        nn.Linear(n_hidden,48), # layer 6\n",
    "        )#48\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        residual1 = x   #Save input as residual\n",
    "\n",
    "        \n",
    "        x = self.block2(x)\n",
    "        \n",
    "        #x += residual1 #add input to output of block2\n",
    "        residual2 = x  #save output of block1 as residual\n",
    "        \n",
    "        x = self.block3(x)\n",
    "        #x += residual2 #add input to output of block2\n",
    "        \n",
    "        x = self.block4(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model):\n",
    "    model.train()\n",
    "    for data,target in zip(train_inputs.split(batch_size),train_targets.split(batch_size)):\n",
    "        output = model(data)\n",
    "        #print(100)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch%10 == 0):\n",
    "        train_losses.append(loss.item())\n",
    "        print(\"[EPOCH]: %i, [LOSS]: %.6f\" % (epoch, loss.item()))\n",
    "        \n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    for data,target in zip(test_inputs.split(batch_size),test_targets.split(batch_size)):\n",
    "        output = model(data)\n",
    "#     for _ in range(10):\n",
    "#         model(torch.FloatTensor(2,28))#https://discuss.pytorch.org/t/model-eval-gives-incorrect-loss-for-model-with-batchnorm-layers/7561/2\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data,target in zip(test_inputs.split(batch_size),test_targets.split(batch_size)):\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target,reduction='sum').item()#/test_inputs.shape[0]  # sum up batch loss instead of averaging by multplying the batch size                                                           \n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    test_loss /= test_inputs.shape[0]\n",
    "    test_losses.append(test_loss)\n",
    "    accuracy = 100. * correct / test_inputs.shape[0]\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy:({:.0f}%)\\n'.format(test_loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = model(100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimization paramaters\n",
    "lr = 1e-4\n",
    "lambda_l2 = 1e-5\n",
    "nb_epoches = 1000\n",
    "batch_size =  60\n",
    "#criterion = torch.nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(Net.parameters(), lr=lr, momentum=0.5) # built-in L2\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lambda_l2) # built-in L2\n",
    "optimizer = torch.optim.Adam(Net.parameters(), lr=lr, weight_decay=lambda_l2) # built-in L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'checkpoint_c.pth.tar'\n",
    "epoch = 0\n",
    "test_losses = []\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "=> no checkpoint found at 'checkpoint_c.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "# save and load the model \n",
    "# print(file_name)\n",
    "import os \n",
    "if file_name:\n",
    "        print('in')\n",
    "        if os.path.isfile(file_name):\n",
    "            print(\"=> loading checkpoint '{}'\".format(file_name))\n",
    "            checkpoint = torch.load(file_name)\n",
    "            epoch = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            test_losses = checkpoint['test_losses']\n",
    "            train_losses = checkpoint['train_losses']\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(file_name, checkpoint['epoch']))\n",
    "            model.eval() #https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/8\n",
    "\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(file_name))\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint_c.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    file_name = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH]: 10, [LOSS]: 3.341590\n",
      "\n",
      "Test set: Average loss: 3.5296, Accuracy:(8%)\n",
      "\n",
      "[EPOCH]: 20, [LOSS]: 3.223444\n",
      "[EPOCH]: 30, [LOSS]: 3.084348\n",
      "\n",
      "Test set: Average loss: 3.6799, Accuracy:(7%)\n",
      "\n",
      "[EPOCH]: 40, [LOSS]: 2.899253\n",
      "[EPOCH]: 50, [LOSS]: 2.717137\n",
      "\n",
      "Test set: Average loss: 3.9347, Accuracy:(7%)\n",
      "\n",
      "[EPOCH]: 60, [LOSS]: 2.542610\n",
      "[EPOCH]: 70, [LOSS]: 2.385568\n",
      "\n",
      "Test set: Average loss: 4.2862, Accuracy:(7%)\n",
      "\n",
      "[EPOCH]: 80, [LOSS]: 2.228365\n",
      "[EPOCH]: 90, [LOSS]: 2.067868\n",
      "\n",
      "Test set: Average loss: 4.6786, Accuracy:(6%)\n",
      "\n",
      "[EPOCH]: 100, [LOSS]: 1.946160\n",
      "[EPOCH]: 110, [LOSS]: 1.833320\n",
      "\n",
      "Test set: Average loss: 5.1304, Accuracy:(6%)\n",
      "\n",
      "[EPOCH]: 120, [LOSS]: 1.712629\n",
      "[EPOCH]: 130, [LOSS]: 1.605096\n",
      "\n",
      "Test set: Average loss: 5.6187, Accuracy:(6%)\n",
      "\n",
      "[EPOCH]: 140, [LOSS]: 1.519373\n",
      "[EPOCH]: 150, [LOSS]: 1.406126\n",
      "\n",
      "Test set: Average loss: 6.2088, Accuracy:(6%)\n",
      "\n",
      "[EPOCH]: 160, [LOSS]: 1.336046\n",
      "[EPOCH]: 170, [LOSS]: 1.270197\n",
      "\n",
      "Test set: Average loss: 6.8251, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 180, [LOSS]: 1.220226\n",
      "[EPOCH]: 190, [LOSS]: 1.132242\n",
      "\n",
      "Test set: Average loss: 7.4422, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 200, [LOSS]: 1.060597\n",
      "[EPOCH]: 210, [LOSS]: 0.982600\n",
      "\n",
      "Test set: Average loss: 8.1462, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 220, [LOSS]: 0.923878\n",
      "[EPOCH]: 230, [LOSS]: 0.898787\n",
      "\n",
      "Test set: Average loss: 8.7409, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 240, [LOSS]: 0.894211\n",
      "[EPOCH]: 250, [LOSS]: 0.776434\n",
      "\n",
      "Test set: Average loss: 9.3828, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 260, [LOSS]: 0.764444\n",
      "[EPOCH]: 270, [LOSS]: 0.695185\n",
      "\n",
      "Test set: Average loss: 9.9631, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 280, [LOSS]: 0.679727\n",
      "[EPOCH]: 290, [LOSS]: 0.621833\n",
      "\n",
      "Test set: Average loss: 10.5169, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 300, [LOSS]: 0.626105\n",
      "[EPOCH]: 310, [LOSS]: 0.541439\n",
      "\n",
      "Test set: Average loss: 11.1016, Accuracy:(5%)\n",
      "\n",
      "[EPOCH]: 320, [LOSS]: 0.622209\n",
      "[EPOCH]: 330, [LOSS]: 0.527356\n",
      "\n",
      "Test set: Average loss: 11.4238, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 340, [LOSS]: 0.594030\n",
      "[EPOCH]: 350, [LOSS]: 0.544847\n",
      "\n",
      "Test set: Average loss: 11.8316, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 360, [LOSS]: 0.498013\n",
      "[EPOCH]: 370, [LOSS]: 0.496598\n",
      "\n",
      "Test set: Average loss: 12.2628, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 380, [LOSS]: 0.453771\n",
      "[EPOCH]: 390, [LOSS]: 0.454939\n",
      "\n",
      "Test set: Average loss: 12.6519, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 400, [LOSS]: 0.466657\n",
      "[EPOCH]: 410, [LOSS]: 0.451553\n",
      "\n",
      "Test set: Average loss: 12.7971, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 420, [LOSS]: 0.456806\n",
      "[EPOCH]: 430, [LOSS]: 0.488933\n",
      "\n",
      "Test set: Average loss: 13.0822, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 440, [LOSS]: 0.478493\n",
      "[EPOCH]: 450, [LOSS]: 0.434303\n",
      "\n",
      "Test set: Average loss: 13.3308, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 460, [LOSS]: 0.391474\n",
      "[EPOCH]: 470, [LOSS]: 0.442351\n",
      "\n",
      "Test set: Average loss: 13.5480, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 480, [LOSS]: 0.407512\n",
      "[EPOCH]: 490, [LOSS]: 0.388846\n",
      "\n",
      "Test set: Average loss: 13.6692, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 500, [LOSS]: 0.397352\n",
      "[EPOCH]: 510, [LOSS]: 0.452292\n",
      "\n",
      "Test set: Average loss: 13.7875, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 520, [LOSS]: 0.375389\n",
      "[EPOCH]: 530, [LOSS]: 0.410250\n",
      "\n",
      "Test set: Average loss: 13.8482, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 540, [LOSS]: 0.418377\n",
      "[EPOCH]: 550, [LOSS]: 0.412124\n",
      "\n",
      "Test set: Average loss: 14.0255, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 560, [LOSS]: 0.383923\n",
      "[EPOCH]: 570, [LOSS]: 0.396631\n",
      "\n",
      "Test set: Average loss: 14.2372, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 580, [LOSS]: 0.361273\n",
      "[EPOCH]: 590, [LOSS]: 0.348235\n",
      "\n",
      "Test set: Average loss: 14.2718, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 600, [LOSS]: 0.348881\n",
      "[EPOCH]: 610, [LOSS]: 0.442286\n",
      "\n",
      "Test set: Average loss: 14.3563, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 620, [LOSS]: 0.347112\n",
      "[EPOCH]: 630, [LOSS]: 0.378082\n",
      "\n",
      "Test set: Average loss: 14.5729, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 640, [LOSS]: 0.332539\n",
      "[EPOCH]: 650, [LOSS]: 0.344519\n",
      "\n",
      "Test set: Average loss: 14.6624, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 660, [LOSS]: 0.370720\n",
      "[EPOCH]: 670, [LOSS]: 0.349419\n",
      "\n",
      "Test set: Average loss: 14.8252, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 680, [LOSS]: 0.356069\n",
      "[EPOCH]: 690, [LOSS]: 0.418333\n",
      "\n",
      "Test set: Average loss: 14.9196, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 700, [LOSS]: 0.431692\n",
      "[EPOCH]: 710, [LOSS]: 0.331891\n",
      "\n",
      "Test set: Average loss: 15.1067, Accuracy:(4%)\n",
      "\n",
      "[EPOCH]: 720, [LOSS]: 0.455086\n",
      "[EPOCH]: 730, [LOSS]: 0.350792\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-60557dd5ef12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-8a6853fb74c5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while (1):\n",
    "    train(epoch,Net)\n",
    "    epoch += 1\n",
    "    if(epoch%20 ==0):\n",
    "        test(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('no of iterations')\n",
    "plt.ylabel('Cross Entropy loss ')\n",
    "plt.savefig('Training_error - predict country - batch norm - no residual - batch statics False .png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
